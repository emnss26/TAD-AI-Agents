{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 2619,
  "global_step": 7857,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.038182512409316534,
      "grad_norm": 1.6764992475509644,
      "learning_rate": 9.446564885496183e-06,
      "loss": 2.2189,
      "step": 100
    },
    {
      "epoch": 0.07636502481863307,
      "grad_norm": 2.486726999282837,
      "learning_rate": 1.898854961832061e-05,
      "loss": 1.6924,
      "step": 200
    },
    {
      "epoch": 0.1145475372279496,
      "grad_norm": 2.9003982543945312,
      "learning_rate": 2.8530534351145037e-05,
      "loss": 1.1468,
      "step": 300
    },
    {
      "epoch": 0.15273004963726614,
      "grad_norm": 3.2250168323516846,
      "learning_rate": 3.807251908396946e-05,
      "loss": 0.9055,
      "step": 400
    },
    {
      "epoch": 0.19091256204658266,
      "grad_norm": 4.8174614906311035,
      "learning_rate": 4.7614503816793896e-05,
      "loss": 0.8057,
      "step": 500
    },
    {
      "epoch": 0.2290950744558992,
      "grad_norm": 4.285326957702637,
      "learning_rate": 5.715648854961833e-05,
      "loss": 0.7258,
      "step": 600
    },
    {
      "epoch": 0.26727758686521574,
      "grad_norm": 3.4133543968200684,
      "learning_rate": 6.669847328244275e-05,
      "loss": 0.6014,
      "step": 700
    },
    {
      "epoch": 0.30546009927453227,
      "grad_norm": 4.052816390991211,
      "learning_rate": 7.624045801526718e-05,
      "loss": 0.5832,
      "step": 800
    },
    {
      "epoch": 0.3436426116838488,
      "grad_norm": 3.067519187927246,
      "learning_rate": 8.57824427480916e-05,
      "loss": 0.5648,
      "step": 900
    },
    {
      "epoch": 0.3818251240931653,
      "grad_norm": 1.9876822233200073,
      "learning_rate": 9.532442748091603e-05,
      "loss": 0.5171,
      "step": 1000
    },
    {
      "epoch": 0.42000763650248185,
      "grad_norm": 2.2709476947784424,
      "learning_rate": 9.999278011123734e-05,
      "loss": 0.449,
      "step": 1100
    },
    {
      "epoch": 0.4581901489117984,
      "grad_norm": 2.147949695587158,
      "learning_rate": 9.993672052414209e-05,
      "loss": 0.458,
      "step": 1200
    },
    {
      "epoch": 0.4963726613211149,
      "grad_norm": 3.778149127960205,
      "learning_rate": 9.982521874025609e-05,
      "loss": 0.4246,
      "step": 1300
    },
    {
      "epoch": 0.5345551737304315,
      "grad_norm": 2.3903956413269043,
      "learning_rate": 9.965839855432961e-05,
      "loss": 0.3434,
      "step": 1400
    },
    {
      "epoch": 0.572737686139748,
      "grad_norm": 2.2084434032440186,
      "learning_rate": 9.943644517831647e-05,
      "loss": 0.3909,
      "step": 1500
    },
    {
      "epoch": 0.6109201985490645,
      "grad_norm": 2.891162633895874,
      "learning_rate": 9.91596050357427e-05,
      "loss": 0.3552,
      "step": 1600
    },
    {
      "epoch": 0.649102710958381,
      "grad_norm": 1.4167734384536743,
      "learning_rate": 9.882818548811514e-05,
      "loss": 0.3526,
      "step": 1700
    },
    {
      "epoch": 0.6872852233676976,
      "grad_norm": 4.028363227844238,
      "learning_rate": 9.844255449367343e-05,
      "loss": 0.3653,
      "step": 1800
    },
    {
      "epoch": 0.7254677357770142,
      "grad_norm": 1.7593623399734497,
      "learning_rate": 9.800314019886489e-05,
      "loss": 0.3404,
      "step": 1900
    },
    {
      "epoch": 0.7636502481863306,
      "grad_norm": 2.0633656978607178,
      "learning_rate": 9.751043046299527e-05,
      "loss": 0.3084,
      "step": 2000
    },
    {
      "epoch": 0.8018327605956472,
      "grad_norm": 2.8214595317840576,
      "learning_rate": 9.696497231658338e-05,
      "loss": 0.2877,
      "step": 2100
    },
    {
      "epoch": 0.8400152730049637,
      "grad_norm": 1.2986335754394531,
      "learning_rate": 9.636737135402101e-05,
      "loss": 0.2759,
      "step": 2200
    },
    {
      "epoch": 0.8781977854142803,
      "grad_norm": 1.4396823644638062,
      "learning_rate": 9.571829106121237e-05,
      "loss": 0.2515,
      "step": 2300
    },
    {
      "epoch": 0.9163802978235968,
      "grad_norm": 1.6288127899169922,
      "learning_rate": 9.50184520789394e-05,
      "loss": 0.2637,
      "step": 2400
    },
    {
      "epoch": 0.9545628102329133,
      "grad_norm": 1.6613880395889282,
      "learning_rate": 9.426863140277106e-05,
      "loss": 0.264,
      "step": 2500
    },
    {
      "epoch": 0.9927453226422298,
      "grad_norm": 2.0522072315216064,
      "learning_rate": 9.346966152040484e-05,
      "loss": 0.2403,
      "step": 2600
    },
    {
      "epoch": 1.0309278350515463,
      "grad_norm": 1.2777150869369507,
      "learning_rate": 9.262242948739786e-05,
      "loss": 0.2312,
      "step": 2700
    },
    {
      "epoch": 1.069110347460863,
      "grad_norm": 1.3850141763687134,
      "learning_rate": 9.172787594231446e-05,
      "loss": 0.2062,
      "step": 2800
    },
    {
      "epoch": 1.1072928598701794,
      "grad_norm": 1.2720171213150024,
      "learning_rate": 9.078699406238306e-05,
      "loss": 0.2122,
      "step": 2900
    },
    {
      "epoch": 1.145475372279496,
      "grad_norm": 0.6891619563102722,
      "learning_rate": 8.98008284608221e-05,
      "loss": 0.2145,
      "step": 3000
    },
    {
      "epoch": 1.1836578846888126,
      "grad_norm": 0.8623002171516418,
      "learning_rate": 8.877047402705912e-05,
      "loss": 0.1886,
      "step": 3100
    },
    {
      "epoch": 1.221840397098129,
      "grad_norm": 2.8194868564605713,
      "learning_rate": 8.769707471113096e-05,
      "loss": 0.1995,
      "step": 3200
    },
    {
      "epoch": 1.2600229095074456,
      "grad_norm": 1.7076756954193115,
      "learning_rate": 8.658182225361413e-05,
      "loss": 0.1926,
      "step": 3300
    },
    {
      "epoch": 1.2982054219167622,
      "grad_norm": 1.6895496845245361,
      "learning_rate": 8.542595486249614e-05,
      "loss": 0.1745,
      "step": 3400
    },
    {
      "epoch": 1.3363879343260787,
      "grad_norm": 1.3918150663375854,
      "learning_rate": 8.42307558384561e-05,
      "loss": 0.1874,
      "step": 3500
    },
    {
      "epoch": 1.3745704467353952,
      "grad_norm": 1.293961763381958,
      "learning_rate": 8.299755215008145e-05,
      "loss": 0.1732,
      "step": 3600
    },
    {
      "epoch": 1.4127529591447117,
      "grad_norm": 1.4633387327194214,
      "learning_rate": 8.17277129606023e-05,
      "loss": 0.1798,
      "step": 3700
    },
    {
      "epoch": 1.4509354715540281,
      "grad_norm": 0.8115977644920349,
      "learning_rate": 8.042264810777925e-05,
      "loss": 0.1782,
      "step": 3800
    },
    {
      "epoch": 1.4891179839633448,
      "grad_norm": 0.9987619519233704,
      "learning_rate": 7.908380653863236e-05,
      "loss": 0.1725,
      "step": 3900
    },
    {
      "epoch": 1.5273004963726613,
      "grad_norm": 2.1901659965515137,
      "learning_rate": 7.771267470074908e-05,
      "loss": 0.1627,
      "step": 4000
    },
    {
      "epoch": 1.5654830087819778,
      "grad_norm": 1.4572715759277344,
      "learning_rate": 7.631077489195722e-05,
      "loss": 0.1455,
      "step": 4100
    },
    {
      "epoch": 1.6036655211912945,
      "grad_norm": 3.492760181427002,
      "learning_rate": 7.487966357019524e-05,
      "loss": 0.1742,
      "step": 4200
    },
    {
      "epoch": 1.641848033600611,
      "grad_norm": 1.8372348546981812,
      "learning_rate": 7.342092962545624e-05,
      "loss": 0.159,
      "step": 4300
    },
    {
      "epoch": 1.6800305460099274,
      "grad_norm": 0.7955257892608643,
      "learning_rate": 7.193619261572447e-05,
      "loss": 0.1494,
      "step": 4400
    },
    {
      "epoch": 1.718213058419244,
      "grad_norm": 2.906737804412842,
      "learning_rate": 7.042710096886243e-05,
      "loss": 0.1282,
      "step": 4500
    },
    {
      "epoch": 1.7563955708285606,
      "grad_norm": 0.5651674270629883,
      "learning_rate": 6.889533015244554e-05,
      "loss": 0.1566,
      "step": 4600
    },
    {
      "epoch": 1.794578083237877,
      "grad_norm": 1.2793604135513306,
      "learning_rate": 6.734258081357579e-05,
      "loss": 0.1224,
      "step": 4700
    },
    {
      "epoch": 1.8327605956471937,
      "grad_norm": 0.8531414270401001,
      "learning_rate": 6.577057689073992e-05,
      "loss": 0.1453,
      "step": 4800
    },
    {
      "epoch": 1.87094310805651,
      "grad_norm": 1.566002607345581,
      "learning_rate": 6.418106369980829e-05,
      "loss": 0.1608,
      "step": 4900
    },
    {
      "epoch": 1.9091256204658267,
      "grad_norm": 2.6007189750671387,
      "learning_rate": 6.257580599629965e-05,
      "loss": 0.1309,
      "step": 5000
    },
    {
      "epoch": 1.9473081328751431,
      "grad_norm": 0.9977540373802185,
      "learning_rate": 6.095658601606298e-05,
      "loss": 0.145,
      "step": 5100
    },
    {
      "epoch": 1.9854906452844596,
      "grad_norm": 2.359375,
      "learning_rate": 5.9325201496551776e-05,
      "loss": 0.1516,
      "step": 5200
    },
    {
      "epoch": 2.0236731576937763,
      "grad_norm": 0.9540761709213257,
      "learning_rate": 5.768346368088777e-05,
      "loss": 0.1094,
      "step": 5300
    },
    {
      "epoch": 2.0618556701030926,
      "grad_norm": 0.9153182506561279,
      "learning_rate": 5.603319530693003e-05,
      "loss": 0.1106,
      "step": 5400
    },
    {
      "epoch": 2.1000381825124093,
      "grad_norm": 0.5962581038475037,
      "learning_rate": 5.437622858358182e-05,
      "loss": 0.1098,
      "step": 5500
    },
    {
      "epoch": 2.138220694921726,
      "grad_norm": 0.8261978030204773,
      "learning_rate": 5.271440315658259e-05,
      "loss": 0.1213,
      "step": 5600
    },
    {
      "epoch": 2.176403207331042,
      "grad_norm": 0.6771310567855835,
      "learning_rate": 5.104956406604282e-05,
      "loss": 0.1049,
      "step": 5700
    },
    {
      "epoch": 2.214585719740359,
      "grad_norm": 0.7155588269233704,
      "learning_rate": 4.938355969799018e-05,
      "loss": 0.106,
      "step": 5800
    },
    {
      "epoch": 2.2527682321496756,
      "grad_norm": 0.8436275124549866,
      "learning_rate": 4.771823973220055e-05,
      "loss": 0.1155,
      "step": 5900
    },
    {
      "epoch": 2.290950744558992,
      "grad_norm": 0.6511616110801697,
      "learning_rate": 4.6055453088592814e-05,
      "loss": 0.1118,
      "step": 6000
    },
    {
      "epoch": 2.3291332569683085,
      "grad_norm": 1.228546380996704,
      "learning_rate": 4.43970458744674e-05,
      "loss": 0.1139,
      "step": 6100
    },
    {
      "epoch": 2.3673157693776252,
      "grad_norm": 2.3141565322875977,
      "learning_rate": 4.274485933486719e-05,
      "loss": 0.1125,
      "step": 6200
    },
    {
      "epoch": 2.4054982817869415,
      "grad_norm": 0.5066812038421631,
      "learning_rate": 4.1100727808337106e-05,
      "loss": 0.1144,
      "step": 6300
    },
    {
      "epoch": 2.443680794196258,
      "grad_norm": 0.8686688542366028,
      "learning_rate": 3.946647669035138e-05,
      "loss": 0.1092,
      "step": 6400
    },
    {
      "epoch": 2.4818633066055744,
      "grad_norm": 1.2025123834609985,
      "learning_rate": 3.784392040667004e-05,
      "loss": 0.1037,
      "step": 6500
    },
    {
      "epoch": 2.520045819014891,
      "grad_norm": 0.6857919096946716,
      "learning_rate": 3.623486039887432e-05,
      "loss": 0.1057,
      "step": 6600
    },
    {
      "epoch": 2.558228331424208,
      "grad_norm": 2.4090416431427,
      "learning_rate": 3.464108312431791e-05,
      "loss": 0.1031,
      "step": 6700
    },
    {
      "epoch": 2.5964108438335245,
      "grad_norm": 1.5582002401351929,
      "learning_rate": 3.306435807271442e-05,
      "loss": 0.1096,
      "step": 6800
    },
    {
      "epoch": 2.6345933562428407,
      "grad_norm": 0.8638888597488403,
      "learning_rate": 3.150643580156297e-05,
      "loss": 0.0971,
      "step": 6900
    },
    {
      "epoch": 2.6727758686521574,
      "grad_norm": 0.879662036895752,
      "learning_rate": 2.9969045992593435e-05,
      "loss": 0.1062,
      "step": 7000
    },
    {
      "epoch": 2.7109583810614737,
      "grad_norm": 0.6241223216056824,
      "learning_rate": 2.8453895531388998e-05,
      "loss": 0.1057,
      "step": 7100
    },
    {
      "epoch": 2.7491408934707904,
      "grad_norm": 0.4637150466442108,
      "learning_rate": 2.696266661231799e-05,
      "loss": 0.0927,
      "step": 7200
    },
    {
      "epoch": 2.787323405880107,
      "grad_norm": 1.5936850309371948,
      "learning_rate": 2.5497014870879125e-05,
      "loss": 0.0983,
      "step": 7300
    },
    {
      "epoch": 2.8255059182894233,
      "grad_norm": 0.7839274406433105,
      "learning_rate": 2.4058567545533877e-05,
      "loss": 0.0949,
      "step": 7400
    },
    {
      "epoch": 2.86368843069874,
      "grad_norm": 2.466066360473633,
      "learning_rate": 2.2648921671066426e-05,
      "loss": 0.0949,
      "step": 7500
    },
    {
      "epoch": 2.9018709431080563,
      "grad_norm": 0.696943998336792,
      "learning_rate": 2.1269642305477305e-05,
      "loss": 0.0893,
      "step": 7600
    },
    {
      "epoch": 2.940053455517373,
      "grad_norm": 0.8303351998329163,
      "learning_rate": 1.99222607923793e-05,
      "loss": 0.0906,
      "step": 7700
    },
    {
      "epoch": 2.9782359679266897,
      "grad_norm": 0.7874455451965332,
      "learning_rate": 1.8608273060824527e-05,
      "loss": 0.0874,
      "step": 7800
    }
  ],
  "logging_steps": 100,
  "max_steps": 10476,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 2619,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.283637033566208e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
