{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 2619,
  "global_step": 5238,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.038182512409316534,
      "grad_norm": 1.6764992475509644,
      "learning_rate": 9.446564885496183e-06,
      "loss": 2.2189,
      "step": 100
    },
    {
      "epoch": 0.07636502481863307,
      "grad_norm": 2.486726999282837,
      "learning_rate": 1.898854961832061e-05,
      "loss": 1.6924,
      "step": 200
    },
    {
      "epoch": 0.1145475372279496,
      "grad_norm": 2.9003982543945312,
      "learning_rate": 2.8530534351145037e-05,
      "loss": 1.1468,
      "step": 300
    },
    {
      "epoch": 0.15273004963726614,
      "grad_norm": 3.2250168323516846,
      "learning_rate": 3.807251908396946e-05,
      "loss": 0.9055,
      "step": 400
    },
    {
      "epoch": 0.19091256204658266,
      "grad_norm": 4.8174614906311035,
      "learning_rate": 4.7614503816793896e-05,
      "loss": 0.8057,
      "step": 500
    },
    {
      "epoch": 0.2290950744558992,
      "grad_norm": 4.285326957702637,
      "learning_rate": 5.715648854961833e-05,
      "loss": 0.7258,
      "step": 600
    },
    {
      "epoch": 0.26727758686521574,
      "grad_norm": 3.4133543968200684,
      "learning_rate": 6.669847328244275e-05,
      "loss": 0.6014,
      "step": 700
    },
    {
      "epoch": 0.30546009927453227,
      "grad_norm": 4.052816390991211,
      "learning_rate": 7.624045801526718e-05,
      "loss": 0.5832,
      "step": 800
    },
    {
      "epoch": 0.3436426116838488,
      "grad_norm": 3.067519187927246,
      "learning_rate": 8.57824427480916e-05,
      "loss": 0.5648,
      "step": 900
    },
    {
      "epoch": 0.3818251240931653,
      "grad_norm": 1.9876822233200073,
      "learning_rate": 9.532442748091603e-05,
      "loss": 0.5171,
      "step": 1000
    },
    {
      "epoch": 0.42000763650248185,
      "grad_norm": 2.2709476947784424,
      "learning_rate": 9.999278011123734e-05,
      "loss": 0.449,
      "step": 1100
    },
    {
      "epoch": 0.4581901489117984,
      "grad_norm": 2.147949695587158,
      "learning_rate": 9.993672052414209e-05,
      "loss": 0.458,
      "step": 1200
    },
    {
      "epoch": 0.4963726613211149,
      "grad_norm": 3.778149127960205,
      "learning_rate": 9.982521874025609e-05,
      "loss": 0.4246,
      "step": 1300
    },
    {
      "epoch": 0.5345551737304315,
      "grad_norm": 2.3903956413269043,
      "learning_rate": 9.965839855432961e-05,
      "loss": 0.3434,
      "step": 1400
    },
    {
      "epoch": 0.572737686139748,
      "grad_norm": 2.2084434032440186,
      "learning_rate": 9.943644517831647e-05,
      "loss": 0.3909,
      "step": 1500
    },
    {
      "epoch": 0.6109201985490645,
      "grad_norm": 2.891162633895874,
      "learning_rate": 9.91596050357427e-05,
      "loss": 0.3552,
      "step": 1600
    },
    {
      "epoch": 0.649102710958381,
      "grad_norm": 1.4167734384536743,
      "learning_rate": 9.882818548811514e-05,
      "loss": 0.3526,
      "step": 1700
    },
    {
      "epoch": 0.6872852233676976,
      "grad_norm": 4.028363227844238,
      "learning_rate": 9.844255449367343e-05,
      "loss": 0.3653,
      "step": 1800
    },
    {
      "epoch": 0.7254677357770142,
      "grad_norm": 1.7593623399734497,
      "learning_rate": 9.800314019886489e-05,
      "loss": 0.3404,
      "step": 1900
    },
    {
      "epoch": 0.7636502481863306,
      "grad_norm": 2.0633656978607178,
      "learning_rate": 9.751043046299527e-05,
      "loss": 0.3084,
      "step": 2000
    },
    {
      "epoch": 0.8018327605956472,
      "grad_norm": 2.8214595317840576,
      "learning_rate": 9.696497231658338e-05,
      "loss": 0.2877,
      "step": 2100
    },
    {
      "epoch": 0.8400152730049637,
      "grad_norm": 1.2986335754394531,
      "learning_rate": 9.636737135402101e-05,
      "loss": 0.2759,
      "step": 2200
    },
    {
      "epoch": 0.8781977854142803,
      "grad_norm": 1.4396823644638062,
      "learning_rate": 9.571829106121237e-05,
      "loss": 0.2515,
      "step": 2300
    },
    {
      "epoch": 0.9163802978235968,
      "grad_norm": 1.6288127899169922,
      "learning_rate": 9.50184520789394e-05,
      "loss": 0.2637,
      "step": 2400
    },
    {
      "epoch": 0.9545628102329133,
      "grad_norm": 1.6613880395889282,
      "learning_rate": 9.426863140277106e-05,
      "loss": 0.264,
      "step": 2500
    },
    {
      "epoch": 0.9927453226422298,
      "grad_norm": 2.0522072315216064,
      "learning_rate": 9.346966152040484e-05,
      "loss": 0.2403,
      "step": 2600
    },
    {
      "epoch": 1.0309278350515463,
      "grad_norm": 1.2777150869369507,
      "learning_rate": 9.262242948739786e-05,
      "loss": 0.2312,
      "step": 2700
    },
    {
      "epoch": 1.069110347460863,
      "grad_norm": 1.3850141763687134,
      "learning_rate": 9.172787594231446e-05,
      "loss": 0.2062,
      "step": 2800
    },
    {
      "epoch": 1.1072928598701794,
      "grad_norm": 1.2720171213150024,
      "learning_rate": 9.078699406238306e-05,
      "loss": 0.2122,
      "step": 2900
    },
    {
      "epoch": 1.145475372279496,
      "grad_norm": 0.6891619563102722,
      "learning_rate": 8.98008284608221e-05,
      "loss": 0.2145,
      "step": 3000
    },
    {
      "epoch": 1.1836578846888126,
      "grad_norm": 0.8623002171516418,
      "learning_rate": 8.877047402705912e-05,
      "loss": 0.1886,
      "step": 3100
    },
    {
      "epoch": 1.221840397098129,
      "grad_norm": 2.8194868564605713,
      "learning_rate": 8.769707471113096e-05,
      "loss": 0.1995,
      "step": 3200
    },
    {
      "epoch": 1.2600229095074456,
      "grad_norm": 1.7076756954193115,
      "learning_rate": 8.658182225361413e-05,
      "loss": 0.1926,
      "step": 3300
    },
    {
      "epoch": 1.2982054219167622,
      "grad_norm": 1.6895496845245361,
      "learning_rate": 8.542595486249614e-05,
      "loss": 0.1745,
      "step": 3400
    },
    {
      "epoch": 1.3363879343260787,
      "grad_norm": 1.3918150663375854,
      "learning_rate": 8.42307558384561e-05,
      "loss": 0.1874,
      "step": 3500
    },
    {
      "epoch": 1.3745704467353952,
      "grad_norm": 1.293961763381958,
      "learning_rate": 8.299755215008145e-05,
      "loss": 0.1732,
      "step": 3600
    },
    {
      "epoch": 1.4127529591447117,
      "grad_norm": 1.4633387327194214,
      "learning_rate": 8.17277129606023e-05,
      "loss": 0.1798,
      "step": 3700
    },
    {
      "epoch": 1.4509354715540281,
      "grad_norm": 0.8115977644920349,
      "learning_rate": 8.042264810777925e-05,
      "loss": 0.1782,
      "step": 3800
    },
    {
      "epoch": 1.4891179839633448,
      "grad_norm": 0.9987619519233704,
      "learning_rate": 7.908380653863236e-05,
      "loss": 0.1725,
      "step": 3900
    },
    {
      "epoch": 1.5273004963726613,
      "grad_norm": 2.1901659965515137,
      "learning_rate": 7.771267470074908e-05,
      "loss": 0.1627,
      "step": 4000
    },
    {
      "epoch": 1.5654830087819778,
      "grad_norm": 1.4572715759277344,
      "learning_rate": 7.631077489195722e-05,
      "loss": 0.1455,
      "step": 4100
    },
    {
      "epoch": 1.6036655211912945,
      "grad_norm": 3.492760181427002,
      "learning_rate": 7.487966357019524e-05,
      "loss": 0.1742,
      "step": 4200
    },
    {
      "epoch": 1.641848033600611,
      "grad_norm": 1.8372348546981812,
      "learning_rate": 7.342092962545624e-05,
      "loss": 0.159,
      "step": 4300
    },
    {
      "epoch": 1.6800305460099274,
      "grad_norm": 0.7955257892608643,
      "learning_rate": 7.193619261572447e-05,
      "loss": 0.1494,
      "step": 4400
    },
    {
      "epoch": 1.718213058419244,
      "grad_norm": 2.906737804412842,
      "learning_rate": 7.042710096886243e-05,
      "loss": 0.1282,
      "step": 4500
    },
    {
      "epoch": 1.7563955708285606,
      "grad_norm": 0.5651674270629883,
      "learning_rate": 6.889533015244554e-05,
      "loss": 0.1566,
      "step": 4600
    },
    {
      "epoch": 1.794578083237877,
      "grad_norm": 1.2793604135513306,
      "learning_rate": 6.734258081357579e-05,
      "loss": 0.1224,
      "step": 4700
    },
    {
      "epoch": 1.8327605956471937,
      "grad_norm": 0.8531414270401001,
      "learning_rate": 6.577057689073992e-05,
      "loss": 0.1453,
      "step": 4800
    },
    {
      "epoch": 1.87094310805651,
      "grad_norm": 1.566002607345581,
      "learning_rate": 6.418106369980829e-05,
      "loss": 0.1608,
      "step": 4900
    },
    {
      "epoch": 1.9091256204658267,
      "grad_norm": 2.6007189750671387,
      "learning_rate": 6.257580599629965e-05,
      "loss": 0.1309,
      "step": 5000
    },
    {
      "epoch": 1.9473081328751431,
      "grad_norm": 0.9977540373802185,
      "learning_rate": 6.095658601606298e-05,
      "loss": 0.145,
      "step": 5100
    },
    {
      "epoch": 1.9854906452844596,
      "grad_norm": 2.359375,
      "learning_rate": 5.9325201496551776e-05,
      "loss": 0.1516,
      "step": 5200
    }
  ],
  "logging_steps": 100,
  "max_steps": 10476,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 2619,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.55758022377472e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
