{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 2385,
  "global_step": 9540,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.041928721174004195,
      "grad_norm": 2.5994906425476074,
      "learning_rate": 2.0754716981132076e-05,
      "loss": 2.0012,
      "step": 100
    },
    {
      "epoch": 0.08385744234800839,
      "grad_norm": 1.7156453132629395,
      "learning_rate": 4.171907756813417e-05,
      "loss": 1.3005,
      "step": 200
    },
    {
      "epoch": 0.12578616352201258,
      "grad_norm": 3.142366886138916,
      "learning_rate": 6.268343815513627e-05,
      "loss": 0.9546,
      "step": 300
    },
    {
      "epoch": 0.16771488469601678,
      "grad_norm": 3.3809008598327637,
      "learning_rate": 8.364779874213837e-05,
      "loss": 0.781,
      "step": 400
    },
    {
      "epoch": 0.20964360587002095,
      "grad_norm": 3.515272855758667,
      "learning_rate": 0.00010461215932914045,
      "loss": 0.6804,
      "step": 500
    },
    {
      "epoch": 0.25157232704402516,
      "grad_norm": 2.8625781536102295,
      "learning_rate": 0.00012557651991614257,
      "loss": 0.6243,
      "step": 600
    },
    {
      "epoch": 0.29350104821802936,
      "grad_norm": 1.9044017791748047,
      "learning_rate": 0.00014654088050314464,
      "loss": 0.578,
      "step": 700
    },
    {
      "epoch": 0.33542976939203356,
      "grad_norm": 3.203864812850952,
      "learning_rate": 0.00016750524109014676,
      "loss": 0.5291,
      "step": 800
    },
    {
      "epoch": 0.37735849056603776,
      "grad_norm": 2.1487674713134766,
      "learning_rate": 0.00018846960167714886,
      "loss": 0.4937,
      "step": 900
    },
    {
      "epoch": 0.4192872117400419,
      "grad_norm": 1.911539077758789,
      "learning_rate": 0.00019998644488528747,
      "loss": 0.4448,
      "step": 1000
    },
    {
      "epoch": 0.4612159329140461,
      "grad_norm": 0.7861292362213135,
      "learning_rate": 0.00019985929092404886,
      "loss": 0.3862,
      "step": 1100
    },
    {
      "epoch": 0.5031446540880503,
      "grad_norm": 1.546164631843567,
      "learning_rate": 0.00019959845955929814,
      "loss": 0.3935,
      "step": 1200
    },
    {
      "epoch": 0.5450733752620545,
      "grad_norm": 2.1547462940216064,
      "learning_rate": 0.0001992042999549365,
      "loss": 0.3372,
      "step": 1300
    },
    {
      "epoch": 0.5870020964360587,
      "grad_norm": 1.7000815868377686,
      "learning_rate": 0.00019867733975573298,
      "loss": 0.3171,
      "step": 1400
    },
    {
      "epoch": 0.6289308176100629,
      "grad_norm": 1.5504977703094482,
      "learning_rate": 0.0001980182843809883,
      "loss": 0.3132,
      "step": 1500
    },
    {
      "epoch": 0.6708595387840671,
      "grad_norm": 0.9025423526763916,
      "learning_rate": 0.00019722801608022025,
      "loss": 0.2986,
      "step": 1600
    },
    {
      "epoch": 0.7127882599580713,
      "grad_norm": 1.5046333074569702,
      "learning_rate": 0.00019630759275213357,
      "loss": 0.2614,
      "step": 1700
    },
    {
      "epoch": 0.7547169811320755,
      "grad_norm": 1.9382699728012085,
      "learning_rate": 0.00019525824652845582,
      "loss": 0.271,
      "step": 1800
    },
    {
      "epoch": 0.7966457023060797,
      "grad_norm": 1.9371352195739746,
      "learning_rate": 0.00019408138212453454,
      "loss": 0.2251,
      "step": 1900
    },
    {
      "epoch": 0.8385744234800838,
      "grad_norm": 1.3006455898284912,
      "learning_rate": 0.0001927785749589047,
      "loss": 0.2389,
      "step": 2000
    },
    {
      "epoch": 0.8805031446540881,
      "grad_norm": 1.7421519756317139,
      "learning_rate": 0.00019135156904434228,
      "loss": 0.2037,
      "step": 2100
    },
    {
      "epoch": 0.9224318658280922,
      "grad_norm": 1.588783621788025,
      "learning_rate": 0.0001898022746532285,
      "loss": 0.1939,
      "step": 2200
    },
    {
      "epoch": 0.9643605870020965,
      "grad_norm": 1.0596234798431396,
      "learning_rate": 0.00018813276576034888,
      "loss": 0.1908,
      "step": 2300
    },
    {
      "epoch": 1.0062893081761006,
      "grad_norm": 0.8777531981468201,
      "learning_rate": 0.00018634527726655117,
      "loss": 0.1891,
      "step": 2400
    },
    {
      "epoch": 1.0482180293501049,
      "grad_norm": 1.2260133028030396,
      "learning_rate": 0.00018444220200697817,
      "loss": 0.1702,
      "step": 2500
    },
    {
      "epoch": 1.090146750524109,
      "grad_norm": 2.8844730854034424,
      "learning_rate": 0.0001824260875478807,
      "loss": 0.1601,
      "step": 2600
    },
    {
      "epoch": 1.1320754716981132,
      "grad_norm": 0.9731161594390869,
      "learning_rate": 0.00018029963277629848,
      "loss": 0.1545,
      "step": 2700
    },
    {
      "epoch": 1.1740041928721174,
      "grad_norm": 1.104243278503418,
      "learning_rate": 0.00017806568428717454,
      "loss": 0.142,
      "step": 2800
    },
    {
      "epoch": 1.2159329140461215,
      "grad_norm": 0.891089677810669,
      "learning_rate": 0.00017572723257273885,
      "loss": 0.1601,
      "step": 2900
    },
    {
      "epoch": 1.2578616352201257,
      "grad_norm": 0.9556627869606018,
      "learning_rate": 0.00017328740801926328,
      "loss": 0.1434,
      "step": 3000
    },
    {
      "epoch": 1.29979035639413,
      "grad_norm": 0.7123982310295105,
      "learning_rate": 0.00017074947671654597,
      "loss": 0.1298,
      "step": 3100
    },
    {
      "epoch": 1.3417190775681342,
      "grad_norm": 0.6968879699707031,
      "learning_rate": 0.00016811683608573518,
      "loss": 0.1237,
      "step": 3200
    },
    {
      "epoch": 1.3836477987421385,
      "grad_norm": 4.334710121154785,
      "learning_rate": 0.0001653930103313456,
      "loss": 0.1255,
      "step": 3300
    },
    {
      "epoch": 1.4255765199161425,
      "grad_norm": 2.3555076122283936,
      "learning_rate": 0.00016258164572355494,
      "loss": 0.1239,
      "step": 3400
    },
    {
      "epoch": 1.4675052410901468,
      "grad_norm": 0.6792179346084595,
      "learning_rate": 0.00015968650571709657,
      "loss": 0.1302,
      "step": 3500
    },
    {
      "epoch": 1.509433962264151,
      "grad_norm": 0.4133804142475128,
      "learning_rate": 0.00015671146591328194,
      "loss": 0.112,
      "step": 3600
    },
    {
      "epoch": 1.551362683438155,
      "grad_norm": 1.0765496492385864,
      "learning_rate": 0.0001536605088718973,
      "loss": 0.1199,
      "step": 3700
    },
    {
      "epoch": 1.5932914046121593,
      "grad_norm": 0.6235028505325317,
      "learning_rate": 0.00015053771877991966,
      "loss": 0.1049,
      "step": 3800
    },
    {
      "epoch": 1.6352201257861636,
      "grad_norm": 3.1866455078125,
      "learning_rate": 0.00014734727598418845,
      "loss": 0.119,
      "step": 3900
    },
    {
      "epoch": 1.6771488469601676,
      "grad_norm": 0.8051937818527222,
      "learning_rate": 0.00014409345139535244,
      "loss": 0.1091,
      "step": 4000
    },
    {
      "epoch": 1.719077568134172,
      "grad_norm": 0.9427462220191956,
      "learning_rate": 0.00014078060077058252,
      "loss": 0.103,
      "step": 4100
    },
    {
      "epoch": 1.7610062893081762,
      "grad_norm": 0.4747336208820343,
      "learning_rate": 0.00013741315888270402,
      "loss": 0.1005,
      "step": 4200
    },
    {
      "epoch": 1.8029350104821802,
      "grad_norm": 0.5693800449371338,
      "learning_rate": 0.00013399563358355404,
      "loss": 0.0963,
      "step": 4300
    },
    {
      "epoch": 1.8448637316561844,
      "grad_norm": 0.8074749112129211,
      "learning_rate": 0.00013053259976951133,
      "loss": 0.0969,
      "step": 4400
    },
    {
      "epoch": 1.8867924528301887,
      "grad_norm": 0.6516107320785522,
      "learning_rate": 0.00012702869325727603,
      "loss": 0.0935,
      "step": 4500
    },
    {
      "epoch": 1.9287211740041927,
      "grad_norm": 1.2521246671676636,
      "learning_rate": 0.00012348860457809838,
      "loss": 0.0871,
      "step": 4600
    },
    {
      "epoch": 1.9706498951781972,
      "grad_norm": 0.8937342166900635,
      "learning_rate": 0.00011991707269876312,
      "loss": 0.0853,
      "step": 4700
    },
    {
      "epoch": 2.0125786163522013,
      "grad_norm": 0.49281221628189087,
      "learning_rate": 0.00011631887867773534,
      "loss": 0.083,
      "step": 4800
    },
    {
      "epoch": 2.0545073375262053,
      "grad_norm": 0.5054098963737488,
      "learning_rate": 0.00011269883926496002,
      "loss": 0.0805,
      "step": 4900
    },
    {
      "epoch": 2.0964360587002098,
      "grad_norm": 0.5983806252479553,
      "learning_rate": 0.00010906180045388283,
      "loss": 0.0762,
      "step": 5000
    },
    {
      "epoch": 2.138364779874214,
      "grad_norm": 0.6893150210380554,
      "learning_rate": 0.00010541263099432408,
      "loss": 0.0842,
      "step": 5100
    },
    {
      "epoch": 2.180293501048218,
      "grad_norm": 0.7797946333885193,
      "learning_rate": 0.00010175621587488935,
      "loss": 0.0768,
      "step": 5200
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.7994852662086487,
      "learning_rate": 9.80974497836423e-05,
      "loss": 0.0761,
      "step": 5300
    },
    {
      "epoch": 2.2641509433962264,
      "grad_norm": 0.7705923318862915,
      "learning_rate": 9.444123055579296e-05,
      "loss": 0.0749,
      "step": 5400
    },
    {
      "epoch": 2.3060796645702304,
      "grad_norm": 0.5389242768287659,
      "learning_rate": 9.079245261717315e-05,
      "loss": 0.0682,
      "step": 5500
    },
    {
      "epoch": 2.348008385744235,
      "grad_norm": 0.31373512744903564,
      "learning_rate": 8.715600043227602e-05,
      "loss": 0.0695,
      "step": 5600
    },
    {
      "epoch": 2.389937106918239,
      "grad_norm": 0.44039255380630493,
      "learning_rate": 8.353674196563019e-05,
      "loss": 0.063,
      "step": 5700
    },
    {
      "epoch": 2.431865828092243,
      "grad_norm": 0.49589240550994873,
      "learning_rate": 7.993952216526187e-05,
      "loss": 0.0632,
      "step": 5800
    },
    {
      "epoch": 2.4737945492662474,
      "grad_norm": 0.6348599791526794,
      "learning_rate": 7.636915647696813e-05,
      "loss": 0.0699,
      "step": 5900
    },
    {
      "epoch": 2.5157232704402515,
      "grad_norm": 0.45321667194366455,
      "learning_rate": 7.283042439808345e-05,
      "loss": 0.0627,
      "step": 6000
    },
    {
      "epoch": 2.5576519916142555,
      "grad_norm": 0.3105868995189667,
      "learning_rate": 6.932806307936923e-05,
      "loss": 0.072,
      "step": 6100
    },
    {
      "epoch": 2.59958071278826,
      "grad_norm": 0.5741551518440247,
      "learning_rate": 6.586676098359056e-05,
      "loss": 0.0584,
      "step": 6200
    },
    {
      "epoch": 2.641509433962264,
      "grad_norm": 0.6246700882911682,
      "learning_rate": 6.245115160926975e-05,
      "loss": 0.0646,
      "step": 6300
    },
    {
      "epoch": 2.6834381551362685,
      "grad_norm": 0.3476504385471344,
      "learning_rate": 5.9085807288018045e-05,
      "loss": 0.0642,
      "step": 6400
    },
    {
      "epoch": 2.7253668763102725,
      "grad_norm": 0.5116899609565735,
      "learning_rate": 5.577523306374902e-05,
      "loss": 0.0643,
      "step": 6500
    },
    {
      "epoch": 2.767295597484277,
      "grad_norm": 0.35054099559783936,
      "learning_rate": 5.252386066196702e-05,
      "loss": 0.0597,
      "step": 6600
    },
    {
      "epoch": 2.809224318658281,
      "grad_norm": 0.6988750100135803,
      "learning_rate": 4.933604255720397e-05,
      "loss": 0.0618,
      "step": 6700
    },
    {
      "epoch": 2.851153039832285,
      "grad_norm": 0.6398821473121643,
      "learning_rate": 4.6216046146545975e-05,
      "loss": 0.0587,
      "step": 6800
    },
    {
      "epoch": 2.8930817610062896,
      "grad_norm": 0.7997931838035583,
      "learning_rate": 4.316804803704968e-05,
      "loss": 0.0591,
      "step": 6900
    },
    {
      "epoch": 2.9350104821802936,
      "grad_norm": 0.7486871480941772,
      "learning_rate": 4.0196128454695224e-05,
      "loss": 0.0608,
      "step": 7000
    },
    {
      "epoch": 2.9769392033542976,
      "grad_norm": 0.3197815716266632,
      "learning_rate": 3.730426578236061e-05,
      "loss": 0.0574,
      "step": 7100
    },
    {
      "epoch": 3.018867924528302,
      "grad_norm": 0.5520510673522949,
      "learning_rate": 3.449633123412883e-05,
      "loss": 0.0592,
      "step": 7200
    },
    {
      "epoch": 3.060796645702306,
      "grad_norm": 0.3803163170814514,
      "learning_rate": 3.177608367305783e-05,
      "loss": 0.0557,
      "step": 7300
    },
    {
      "epoch": 3.10272536687631,
      "grad_norm": 0.44519320130348206,
      "learning_rate": 2.9147164579349417e-05,
      "loss": 0.0546,
      "step": 7400
    },
    {
      "epoch": 3.1446540880503147,
      "grad_norm": 0.6024973392486572,
      "learning_rate": 2.6613093175654215e-05,
      "loss": 0.0521,
      "step": 7500
    },
    {
      "epoch": 3.1865828092243187,
      "grad_norm": 0.32437488436698914,
      "learning_rate": 2.4177261716037157e-05,
      "loss": 0.0537,
      "step": 7600
    },
    {
      "epoch": 3.2285115303983227,
      "grad_norm": 0.44720929861068726,
      "learning_rate": 2.1842930944910768e-05,
      "loss": 0.054,
      "step": 7700
    },
    {
      "epoch": 3.270440251572327,
      "grad_norm": 0.49616625905036926,
      "learning_rate": 1.961322573201454e-05,
      "loss": 0.0535,
      "step": 7800
    },
    {
      "epoch": 3.3123689727463312,
      "grad_norm": 0.42490342259407043,
      "learning_rate": 1.7491130889284358e-05,
      "loss": 0.0549,
      "step": 7900
    },
    {
      "epoch": 3.3542976939203353,
      "grad_norm": 0.5546072125434875,
      "learning_rate": 1.5479487175211104e-05,
      "loss": 0.0531,
      "step": 8000
    },
    {
      "epoch": 3.3962264150943398,
      "grad_norm": 0.6676471829414368,
      "learning_rate": 1.35809874920375e-05,
      "loss": 0.0525,
      "step": 8100
    },
    {
      "epoch": 3.438155136268344,
      "grad_norm": 0.3225671947002411,
      "learning_rate": 1.179817328088404e-05,
      "loss": 0.0517,
      "step": 8200
    },
    {
      "epoch": 3.480083857442348,
      "grad_norm": 0.471581369638443,
      "learning_rate": 1.0133431119629289e-05,
      "loss": 0.053,
      "step": 8300
    },
    {
      "epoch": 3.5220125786163523,
      "grad_norm": 0.5226715803146362,
      "learning_rate": 8.588989528099234e-06,
      "loss": 0.0518,
      "step": 8400
    },
    {
      "epoch": 3.5639412997903563,
      "grad_norm": 0.5502456426620483,
      "learning_rate": 7.1669159848421815e-06,
      "loss": 0.0506,
      "step": 8500
    },
    {
      "epoch": 3.6058700209643604,
      "grad_norm": 0.3873569667339325,
      "learning_rate": 5.8691141594827246e-06,
      "loss": 0.0512,
      "step": 8600
    },
    {
      "epoch": 3.647798742138365,
      "grad_norm": 0.4408590495586395,
      "learning_rate": 4.6973213643598635e-06,
      "loss": 0.0494,
      "step": 8700
    },
    {
      "epoch": 3.689727463312369,
      "grad_norm": 0.44694313406944275,
      "learning_rate": 3.65310622886057e-06,
      "loss": 0.0522,
      "step": 8800
    },
    {
      "epoch": 3.731656184486373,
      "grad_norm": 0.44829967617988586,
      "learning_rate": 2.7378665995620666e-06,
      "loss": 0.0503,
      "step": 8900
    },
    {
      "epoch": 3.7735849056603774,
      "grad_norm": 0.5510362386703491,
      "learning_rate": 1.952827668993806e-06,
      "loss": 0.0512,
      "step": 9000
    },
    {
      "epoch": 3.8155136268343814,
      "grad_norm": 0.3015342354774475,
      "learning_rate": 1.2990403355241155e-06,
      "loss": 0.05,
      "step": 9100
    },
    {
      "epoch": 3.8574423480083855,
      "grad_norm": 0.3183254897594452,
      "learning_rate": 7.77379796567057e-07,
      "loss": 0.0471,
      "step": 9200
    },
    {
      "epoch": 3.89937106918239,
      "grad_norm": 0.5309358239173889,
      "learning_rate": 3.885443769927388e-07,
      "loss": 0.0504,
      "step": 9300
    },
    {
      "epoch": 3.941299790356394,
      "grad_norm": 0.3918949067592621,
      "learning_rate": 1.3305459430933421e-07,
      "loss": 0.0521,
      "step": 9400
    },
    {
      "epoch": 3.9832285115303985,
      "grad_norm": 0.5266056060791016,
      "learning_rate": 1.1252461868427322e-08,
      "loss": 0.053,
      "step": 9500
    }
  ],
  "logging_steps": 100,
  "max_steps": 9540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 2385,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.55859708542976e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
