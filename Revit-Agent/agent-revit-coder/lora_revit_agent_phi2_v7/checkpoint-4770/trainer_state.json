{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 2385,
  "global_step": 4770,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.041928721174004195,
      "grad_norm": 2.5994906425476074,
      "learning_rate": 2.0754716981132076e-05,
      "loss": 2.0012,
      "step": 100
    },
    {
      "epoch": 0.08385744234800839,
      "grad_norm": 1.7156453132629395,
      "learning_rate": 4.171907756813417e-05,
      "loss": 1.3005,
      "step": 200
    },
    {
      "epoch": 0.12578616352201258,
      "grad_norm": 3.142366886138916,
      "learning_rate": 6.268343815513627e-05,
      "loss": 0.9546,
      "step": 300
    },
    {
      "epoch": 0.16771488469601678,
      "grad_norm": 3.3809008598327637,
      "learning_rate": 8.364779874213837e-05,
      "loss": 0.781,
      "step": 400
    },
    {
      "epoch": 0.20964360587002095,
      "grad_norm": 3.515272855758667,
      "learning_rate": 0.00010461215932914045,
      "loss": 0.6804,
      "step": 500
    },
    {
      "epoch": 0.25157232704402516,
      "grad_norm": 2.8625781536102295,
      "learning_rate": 0.00012557651991614257,
      "loss": 0.6243,
      "step": 600
    },
    {
      "epoch": 0.29350104821802936,
      "grad_norm": 1.9044017791748047,
      "learning_rate": 0.00014654088050314464,
      "loss": 0.578,
      "step": 700
    },
    {
      "epoch": 0.33542976939203356,
      "grad_norm": 3.203864812850952,
      "learning_rate": 0.00016750524109014676,
      "loss": 0.5291,
      "step": 800
    },
    {
      "epoch": 0.37735849056603776,
      "grad_norm": 2.1487674713134766,
      "learning_rate": 0.00018846960167714886,
      "loss": 0.4937,
      "step": 900
    },
    {
      "epoch": 0.4192872117400419,
      "grad_norm": 1.911539077758789,
      "learning_rate": 0.00019998644488528747,
      "loss": 0.4448,
      "step": 1000
    },
    {
      "epoch": 0.4612159329140461,
      "grad_norm": 0.7861292362213135,
      "learning_rate": 0.00019985929092404886,
      "loss": 0.3862,
      "step": 1100
    },
    {
      "epoch": 0.5031446540880503,
      "grad_norm": 1.546164631843567,
      "learning_rate": 0.00019959845955929814,
      "loss": 0.3935,
      "step": 1200
    },
    {
      "epoch": 0.5450733752620545,
      "grad_norm": 2.1547462940216064,
      "learning_rate": 0.0001992042999549365,
      "loss": 0.3372,
      "step": 1300
    },
    {
      "epoch": 0.5870020964360587,
      "grad_norm": 1.7000815868377686,
      "learning_rate": 0.00019867733975573298,
      "loss": 0.3171,
      "step": 1400
    },
    {
      "epoch": 0.6289308176100629,
      "grad_norm": 1.5504977703094482,
      "learning_rate": 0.0001980182843809883,
      "loss": 0.3132,
      "step": 1500
    },
    {
      "epoch": 0.6708595387840671,
      "grad_norm": 0.9025423526763916,
      "learning_rate": 0.00019722801608022025,
      "loss": 0.2986,
      "step": 1600
    },
    {
      "epoch": 0.7127882599580713,
      "grad_norm": 1.5046333074569702,
      "learning_rate": 0.00019630759275213357,
      "loss": 0.2614,
      "step": 1700
    },
    {
      "epoch": 0.7547169811320755,
      "grad_norm": 1.9382699728012085,
      "learning_rate": 0.00019525824652845582,
      "loss": 0.271,
      "step": 1800
    },
    {
      "epoch": 0.7966457023060797,
      "grad_norm": 1.9371352195739746,
      "learning_rate": 0.00019408138212453454,
      "loss": 0.2251,
      "step": 1900
    },
    {
      "epoch": 0.8385744234800838,
      "grad_norm": 1.3006455898284912,
      "learning_rate": 0.0001927785749589047,
      "loss": 0.2389,
      "step": 2000
    },
    {
      "epoch": 0.8805031446540881,
      "grad_norm": 1.7421519756317139,
      "learning_rate": 0.00019135156904434228,
      "loss": 0.2037,
      "step": 2100
    },
    {
      "epoch": 0.9224318658280922,
      "grad_norm": 1.588783621788025,
      "learning_rate": 0.0001898022746532285,
      "loss": 0.1939,
      "step": 2200
    },
    {
      "epoch": 0.9643605870020965,
      "grad_norm": 1.0596234798431396,
      "learning_rate": 0.00018813276576034888,
      "loss": 0.1908,
      "step": 2300
    },
    {
      "epoch": 1.0062893081761006,
      "grad_norm": 0.8777531981468201,
      "learning_rate": 0.00018634527726655117,
      "loss": 0.1891,
      "step": 2400
    },
    {
      "epoch": 1.0482180293501049,
      "grad_norm": 1.2260133028030396,
      "learning_rate": 0.00018444220200697817,
      "loss": 0.1702,
      "step": 2500
    },
    {
      "epoch": 1.090146750524109,
      "grad_norm": 2.8844730854034424,
      "learning_rate": 0.0001824260875478807,
      "loss": 0.1601,
      "step": 2600
    },
    {
      "epoch": 1.1320754716981132,
      "grad_norm": 0.9731161594390869,
      "learning_rate": 0.00018029963277629848,
      "loss": 0.1545,
      "step": 2700
    },
    {
      "epoch": 1.1740041928721174,
      "grad_norm": 1.104243278503418,
      "learning_rate": 0.00017806568428717454,
      "loss": 0.142,
      "step": 2800
    },
    {
      "epoch": 1.2159329140461215,
      "grad_norm": 0.891089677810669,
      "learning_rate": 0.00017572723257273885,
      "loss": 0.1601,
      "step": 2900
    },
    {
      "epoch": 1.2578616352201257,
      "grad_norm": 0.9556627869606018,
      "learning_rate": 0.00017328740801926328,
      "loss": 0.1434,
      "step": 3000
    },
    {
      "epoch": 1.29979035639413,
      "grad_norm": 0.7123982310295105,
      "learning_rate": 0.00017074947671654597,
      "loss": 0.1298,
      "step": 3100
    },
    {
      "epoch": 1.3417190775681342,
      "grad_norm": 0.6968879699707031,
      "learning_rate": 0.00016811683608573518,
      "loss": 0.1237,
      "step": 3200
    },
    {
      "epoch": 1.3836477987421385,
      "grad_norm": 4.334710121154785,
      "learning_rate": 0.0001653930103313456,
      "loss": 0.1255,
      "step": 3300
    },
    {
      "epoch": 1.4255765199161425,
      "grad_norm": 2.3555076122283936,
      "learning_rate": 0.00016258164572355494,
      "loss": 0.1239,
      "step": 3400
    },
    {
      "epoch": 1.4675052410901468,
      "grad_norm": 0.6792179346084595,
      "learning_rate": 0.00015968650571709657,
      "loss": 0.1302,
      "step": 3500
    },
    {
      "epoch": 1.509433962264151,
      "grad_norm": 0.4133804142475128,
      "learning_rate": 0.00015671146591328194,
      "loss": 0.112,
      "step": 3600
    },
    {
      "epoch": 1.551362683438155,
      "grad_norm": 1.0765496492385864,
      "learning_rate": 0.0001536605088718973,
      "loss": 0.1199,
      "step": 3700
    },
    {
      "epoch": 1.5932914046121593,
      "grad_norm": 0.6235028505325317,
      "learning_rate": 0.00015053771877991966,
      "loss": 0.1049,
      "step": 3800
    },
    {
      "epoch": 1.6352201257861636,
      "grad_norm": 3.1866455078125,
      "learning_rate": 0.00014734727598418845,
      "loss": 0.119,
      "step": 3900
    },
    {
      "epoch": 1.6771488469601676,
      "grad_norm": 0.8051937818527222,
      "learning_rate": 0.00014409345139535244,
      "loss": 0.1091,
      "step": 4000
    },
    {
      "epoch": 1.719077568134172,
      "grad_norm": 0.9427462220191956,
      "learning_rate": 0.00014078060077058252,
      "loss": 0.103,
      "step": 4100
    },
    {
      "epoch": 1.7610062893081762,
      "grad_norm": 0.4747336208820343,
      "learning_rate": 0.00013741315888270402,
      "loss": 0.1005,
      "step": 4200
    },
    {
      "epoch": 1.8029350104821802,
      "grad_norm": 0.5693800449371338,
      "learning_rate": 0.00013399563358355404,
      "loss": 0.0963,
      "step": 4300
    },
    {
      "epoch": 1.8448637316561844,
      "grad_norm": 0.8074749112129211,
      "learning_rate": 0.00013053259976951133,
      "loss": 0.0969,
      "step": 4400
    },
    {
      "epoch": 1.8867924528301887,
      "grad_norm": 0.6516107320785522,
      "learning_rate": 0.00012702869325727603,
      "loss": 0.0935,
      "step": 4500
    },
    {
      "epoch": 1.9287211740041927,
      "grad_norm": 1.2521246671676636,
      "learning_rate": 0.00012348860457809838,
      "loss": 0.0871,
      "step": 4600
    },
    {
      "epoch": 1.9706498951781972,
      "grad_norm": 0.8937342166900635,
      "learning_rate": 0.00011991707269876312,
      "loss": 0.0853,
      "step": 4700
    }
  ],
  "logging_steps": 100,
  "max_steps": 9540,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 2385,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.7929854271488e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
